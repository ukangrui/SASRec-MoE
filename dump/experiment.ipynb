{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from model_exp import SASRec_Exp\n",
    "from utils import *\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from utils import evaluate_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.seed_everything(3407)\n",
    "# seed = 3407\n",
    "# torch.manual_seed(seed)\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "with open('checkpoints/ml1m_popularity.json', 'r') as json_file:\n",
    "    user_popu = json.load(json_file)\n",
    "\n",
    "with open('checkpoints/ml1m_temprature.json', 'r') as json_file:\n",
    "    user_temp = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default='ml-1m',)\n",
    "parser.add_argument('--batch_size', default=1024, type=int)\n",
    "parser.add_argument('--lr', default=1e-3, type=float)\n",
    "parser.add_argument('--maxlen', default=200, type=int)\n",
    "parser.add_argument('--hidden_units', default=50, type=int)\n",
    "parser.add_argument('--num_blocks', default=2, type=int)\n",
    "parser.add_argument('--num_epochs', default=25, type=int)\n",
    "parser.add_argument('--num_heads', default=1, type=int)\n",
    "parser.add_argument('--dropout_rate', default=0.2, type=float)\n",
    "parser.add_argument('--l2_emb', default=0.0, type=float)\n",
    "parser.add_argument('--device', default='cpu', type=str)\n",
    "args, _ = parser.parse_known_args()\n",
    "u2i_index, i2u_index = build_index(args.dataset)\n",
    "dataset = data_partition(args.dataset)\n",
    "[user_train, user_valid, user_test, usernum, itemnum] = dataset\n",
    "\n",
    "model = SASRec_Exp(6040, 3416, args).to(args.device)\n",
    "model.load_state_dict(torch.load('checkpoints/base.pth', map_location=torch.device(args.device)), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = np.random.randint(1,6041, 50)\n",
    "test_users = np.array([1226,  699, 1001,  332, 5342, 5722, 4752, 4850, 2265, 5312, 3234,\n",
    "        107, 1433, 2610, 4373, 6021, 5292, 5316, 1926,  938, 2274, 3189,\n",
    "       3544, 4856, 4026, 3069, 5531, 2117, 6005, 3285, 3651, 4742, 5340,\n",
    "       2001, 5649, 3033, 2218, 5963, 5752, 4942, 1093, 1539, 2256, 1201,\n",
    "       4489, 3186, 2436, 5454,  456, 2995])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_ls = list()\n",
    "ht_ls = list()\n",
    "for user in test_users:\n",
    "    ndcg, ht = evaluate_user(model,dataset,args, test_user=user)\n",
    "    ndcg_ls.append(ndcg)\n",
    "    ht_ls.append(ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11560899612123408\n",
      "0.22\n"
     ]
    }
   ],
   "source": [
    "### BASELINE\n",
    "print(np.mean(ndcg_ls))\n",
    "print(np.mean(ht_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "popu_ndcg_ls = []\n",
    "temp_ndcg_ls = []\n",
    "popu_ht_ls = []\n",
    "temp_ht_ls = []\n",
    "for user in test_users[:]:\n",
    "    user_split_popu = user_popu[str(user)]\n",
    "    user_split_temp = user_temp[str(user)]\n",
    "\n",
    "    popu_dir = 'lora_checkpoint_popu/' + user_split_popu + '/'\n",
    "    temp_dir = 'lora_checkpoint_temp/' + user_split_temp + '/'\n",
    "\n",
    "    max_popu = max([float(i.split('=')[1]) for i in os.listdir(popu_dir)])\n",
    "    max_temp = max([float(i.split('=')[1]) for i in os.listdir(temp_dir)])\n",
    "\n",
    "    ckpt_popu = 'lora_checkpoint_popu/'  + user_split_popu + '/' + 'ndcg=' + str(max_popu)\n",
    "    ckpt_temp = 'lora_checkpoint_temp/'  + user_split_temp + '/' + 'ndcg=' + str(max_temp)\n",
    "    lora_popu = PeftModel.from_pretrained(copy.deepcopy(model), ckpt_popu).merge_and_unload()\n",
    "    lora_temp = PeftModel.from_pretrained(copy.deepcopy(model), ckpt_temp).merge_and_unload()\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        popu_ndcg, popu_ht = evaluate_user(lora_popu, dataset, args, test_user= user)\n",
    "        temp_ndcg, temp_ht = evaluate_user(lora_temp, dataset, args, test_user= user)\n",
    "    \n",
    "    popu_ndcg_ls.append(popu_ndcg)\n",
    "    temp_ndcg_ls.append(temp_ndcg)\n",
    "    popu_ht_ls.append(popu_ht)\n",
    "    temp_ht_ls.append(temp_ht)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POPU\n",
      "0.11603785297076218\n",
      "0.26\n",
      "TEMP\n",
      "0.1087449297755429\n",
      "0.22\n"
     ]
    }
   ],
   "source": [
    "print('POPU')\n",
    "print(np.mean(popu_ndcg_ls))\n",
    "print(np.mean(popu_ht_ls))\n",
    "print('TEMP')\n",
    "print(np.mean(temp_ndcg_ls))\n",
    "print(np.mean(temp_ht_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined with Alpha =  0.5\n",
      "0.12250258583351335\n",
      "0.26\n"
     ]
    }
   ],
   "source": [
    "### Combine\n",
    "from utils import evaluate_user_multiple_model\n",
    "ALPHA = 0.5\n",
    "combined_ndcg_ls = list()\n",
    "combined_ht_ls = list()\n",
    "for user in test_users[:]:\n",
    "    user_split_popu = user_popu[str(user)]\n",
    "    user_split_temp = user_temp[str(user)]\n",
    "\n",
    "    popu_dir = 'lora_checkpoint_popu/' + user_split_popu + '/'\n",
    "    temp_dir = 'lora_checkpoint_temp/' + user_split_temp + '/'\n",
    "\n",
    "    max_popu = max([float(i.split('=')[1]) for i in os.listdir(popu_dir)])\n",
    "    max_temp = max([float(i.split('=')[1]) for i in os.listdir(temp_dir)])\n",
    "\n",
    "    ckpt_popu = 'lora_checkpoint_popu/'  + user_split_popu + '/' + 'ndcg=' + str(max_popu)\n",
    "    ckpt_temp = 'lora_checkpoint_temp/'  + user_split_temp + '/' + 'ndcg=' + str(max_temp)\n",
    "    lora_popu = PeftModel.from_pretrained(copy.deepcopy(model), ckpt_popu).merge_and_unload()\n",
    "    lora_temp = PeftModel.from_pretrained(copy.deepcopy(model), ckpt_temp).merge_and_unload()\n",
    "    \n",
    "    ndcg, ht = evaluate_user_multiple_model([lora_popu, lora_temp], dataset, args, test_user=user, alpha=ALPHA)\n",
    "\n",
    "    combined_ndcg_ls.append(ndcg)\n",
    "    combined_ht_ls.append(ht)\n",
    "    \n",
    "\n",
    "\n",
    "print('Combined with Alpha = ', ALPHA)\n",
    "print(np.mean(combined_ndcg_ls))\n",
    "print(np.mean(combined_ht_ls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
