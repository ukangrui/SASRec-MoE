{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Users: 100%|██████████| 6040/6040 [00:46<00:00, 130.28it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import numpy as np\n",
    "from models.sasrec_base import SASRec\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "def test_variance(model, train_ds, test_ds, split_dict):\n",
    "    all_splits = set(list(split_dict.values()))\n",
    "    ndcg_list = []\n",
    "    ht_list = []\n",
    "    for split in all_splits:\n",
    "        _, lora_test = get_lora_train_test_ds(split_dict, train_ds, test_ds, split)\n",
    "        test_loader  = DataLoader(lora_test, batch_size = 384, shuffle = False, collate_fn = collate_test)\n",
    "        model.eval()\n",
    "        ndcg, ht = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for test_batch in test_loader:\n",
    "                u, seq, pos, test_items, mask = test_batch\n",
    "                batch_ndcg, batch_ht = eval_step(model, u, seq, pos, test_items, mask, topK = 10)\n",
    "                ndcg += batch_ndcg\n",
    "                ht += batch_ht\n",
    "        ndcg /= len(test_ds)\n",
    "        ht /= len(test_ds)\n",
    "        ndcg_list.append(ndcg)\n",
    "        ht_list.append(ht)\n",
    "    return np.std(ndcg_list) * 1000\n",
    "\n",
    "\n",
    "\n",
    "num_u, num_i = get_usr_itm_num('ml-1m')\n",
    "train, test = load_train_test_data_num(load_txt_file('ml-1m'), num_i)\n",
    "model = SASRec(user_num = num_u, item_num = num_i, maxlen = 200, num_blocks = 2, num_heads = 1, hidden_units = 50, dropout_rate = 0.2, device = 'cpu')\n",
    "model.load_state_dict(torch.load(f'checkpoints/{'ml-1m'}-base.pth', map_location=torch.device('cpu')))\n",
    "model = model.to('cpu')\n",
    "\n",
    "split_dict_pop = json.load(open('config/popularity.json'))\n",
    "split_dict_tmp = json.load(open('config/temperature.json'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group by Popularity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.291597902089782"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_variance(model, train, test, split_dict_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group by Sequence Length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2364433656873937"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_variance(model, train, test, split_dict_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group By Random**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8288052669234953"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_variance(model, train, test, dict(zip(np.arange(1, 6041), ['split_' + str(i) for i in np.random.permutation(np.array([[np.arange(1,11)] * 604]).flatten())])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group By Intention Shift**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(load_txt_file('ml-1m').items(), columns=[\"userID\", \"itemID\"])\n",
    "df = df.explode(\"itemID\").reset_index(drop=True)\n",
    "item_pop = df['itemID'].value_counts()\n",
    "low, mid, high = item_pop.quantile([0.33, 0.66, 1.0])\n",
    "labels = [-1, 0, 1]\n",
    "item_pop= pd.cut(item_pop, bins=[-1, low, mid, high], labels=labels, include_lowest=True)\n",
    "df = df.groupby('userID')['itemID'].agg(pop = lambda x: np.var(np.array([item_pop[i] for i in x])))\n",
    "df[\"split\"] = pd.qcut(df[\"pop\"], q=10, labels=[f\"split_{i}\" for i in range(1, 11)])\n",
    "intention_shift_dict = {str(k):v for k,v in df[\"split\"].to_dict().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0848147916681903"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_variance(model, train, test, intention_shift_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
